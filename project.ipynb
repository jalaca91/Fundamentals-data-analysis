{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fundamentals of Data Analysis Project\n",
    "\n",
    "Jaime Lara Carrillo\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This jupyter notebook contains the project from the module: Fundamentals of Data Analysis from ATU Galway's HDip in Data Analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris Fisher Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index\n",
    "\n",
    "1. [Description](#description)\n",
    "2. [Project stages and organisation](#project-stages-and-organisation)  \n",
    "3. [Used tools and libraries](#used-tools-and-libraries)  \n",
    "4. [Data collection](#data-collection)  \n",
    "5. [Data analysis](#data-analysis)  \n",
    "      5.1 [Import and cleaning data](#import-and-cleaning-data)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project consists of analysing and investigating a multivariate dataset introduced\n",
    "by Ronald Fisher in his 1936 paper,_The use of multiple measurements in taxonomic problems_.\n",
    "Although published by Fisher, the data was orignally collected by American botanist, Edgar Anderson,and thats why this is sometimes called Anderson's Iris data set.  \n",
    "Most of the samples where collected on the same day and in the same area (two of the three species).\n",
    "\n",
    "This famous dataset could be the ABC of machine learning and data analysis.  \n",
    "\n",
    "The Iris dataset consists of three species of Iris flowers and 50 samples of each species, giving a sample of a total of 150 records under five attributes, which are:\n",
    "1. Sepal length(cm)\n",
    "2. Sepal width(cm)\n",
    "3. Setal length(cm)\n",
    "4. Petal width(cm)\n",
    "5. Class.\n",
    "\n",
    "The features of this sample are shown in the following image:\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/110190460/234045122-186ab79b-4fbc-4065-ac3e-017c0e1b97ee.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The species are: Setosa, Versicolor and Virginica.  \n",
    "\n",
    "![image](https://user-images.githubusercontent.com/110190460/234044887-5cf5d38c-8ac7-4846-98d3-bbc213e6f32a.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This makes it a multivariate data set, which means that there are two or more variable quantities.\n",
    "As can be seen, despite having a similar shade of colour, these flowers have different attributes in terms\n",
    "of the length of their petals and sepals, which in this project are collected in a file with .csv extension, used by the excel spreadsheet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project stages and organisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The steps of this project can be divided into the following tasks: \n",
    "* Show which technologies and tools will be used\n",
    "* Obtain the dataset and download it\n",
    "* Import the dataset to the integrated development environment (IDE) \n",
    "* Review the dataset and avoid incorrect or incomplete data\n",
    "* Different statistical analyses of the data obtained\n",
    "* Show graphically the result of the previous analysis\n",
    "* Drawing a conclusion from the research carried out\n",
    "* References used in the elaboration of the project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**The project consists of the following files**:  \n",
    "\n",
    "This notebook file contains the entire project, its development and analysis.  \n",
    "The images and the database can be found in the corresponding folders.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Used tools and libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**The project uses the following technologies**:\n",
    "\n",
    "* Python version 3.9.2 as programming language\n",
    "* Excel spreadsheet for the imported data\n",
    "* Visual Studio Code as the Integrated development environment \n",
    "* Jupyter notebook as the folder which contains all the project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The project uses the following libraries**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Numpy  \n",
    "Is used for numerical computation that allows you to work with large, multi-dimensional arrays and matrices of numerical data. It provides a wide range of mathematical functions to operate on these arrays, making it an essential tool for scientific computing, data analysis, and machine learning. To find out more: https://numpy.org/  \n",
    "\n",
    "  \n",
    "* Matplotlib  \n",
    "Is a plotting library for the Python programming language that provides a wide variety of high-quality 2D and 3D graphs and plots. More of this: https://matplotlib.org/  \n",
    "\n",
    "\n",
    "* Seaborn  \n",
    "Is a data visualization library in Python built on top of Matplotlib.  \n",
    "It provides a high-level interface for creating informative and statistical graphics.  \n",
    "https://seaborn.pydata.org/  \n",
    " \n",
    " \n",
    "* Pandas  \n",
    "Is a fast, powerful, flexible and easy to use open source data analysis and manipulation tool, built on top of the Python programming language.\n",
    "https://pandas.pydata.org/  \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, the totality of the libraries used is as follows:  \n",
    "```python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain the dataset we can go to the following link:  \n",
    "https://archive.ics.uci.edu/dataset/53/iris  \n",
    "\n",
    "However, the file is in .txt format and it has no header, so a number of transformations have to be made to it.  \n",
    "To simplify things and given the huge popularity of this dataset, you can find the data already with a header  \n",
    "and in a different format, such as csv. An example is in the following link:  \n",
    "https://datahub.io/machine-learning/iris#resource-iris  \n",
    "I used the snake case before importing the data set just to gave a clearer name to the characteristics of each flower.\n",
    "Once downloaded, the iris flower database is saved in the database folder (files\\database\\iris_csv.csv).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis\n",
    "\n",
    "#### Import and cleaning data\n",
    "Now that the data has been imported, it is important to perform a data cleansing, to remove files that may influence  \n",
    "the result of our analysis, i.e. corrupted data, empty cells, duplicates, incorrect data.  \n",
    "First of all, in the .py file containing our script it is necessary to import the libraries mentioned above to obtain these new functionalities.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we import the libraries, we read the file named \"iris_csv\" into a Pandas Dataframe named \"df\", to access the information it contains.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"files\\database\\iris_csv.csv\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before working with the data frame, it is necessary to do a data cleaning, as the following problems may arise:\n",
    "1. Null files\n",
    "2. Corrupt or atypical files\n",
    "3. Repeated files\n",
    "4. Incompatible files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a crucial process in data analysis to improve data quality and reliability for analysis. \n",
    "It is important for the following reasons:\n",
    "1. Reliability of results: Clean data ensures that analyses and models are based on accurate and consistent information, leading to more reliable conclusions.\n",
    "2. Improved accuracy: By eliminating erroneous or inconsistent data, accuracy metrics in models and analyses are improved.\n",
    "3. Facilitates visualization: Clean data facilitates the creation of clear and understandable visualizations, which helps identify patterns and trends effectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick way to get general information about the structure and content of the DataFrame is to use the .info() method, which provides an informative summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal_length  150 non-null    float64\n",
      " 1   sepal_width   150 non-null    float64\n",
      " 2   petal_length  150 non-null    float64\n",
      " 3   petal_width   150 non-null    float64\n",
      " 4   class         150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "info_iris_db = df.info()\n",
    "print(info_iris_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code shows us details such as the number of rows, the number of columns, the types of data in each column and how much memory is being used.  \n",
    "\n",
    "As for the objective of checking for empty values, it indicates non-null, so the df is complete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also see which values are repeated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "145    False\n",
      "146    False\n",
      "147    False\n",
      "148    False\n",
      "149    False\n",
      "Length: 150, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "duplicates = df.duplicated()\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result only shows the first and last rows, so with the .sum() method to count the number of True (duplicated rows) in that series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of duplicate rows is: 3\n"
     ]
    }
   ],
   "source": [
    "duplicate_count = duplicates.sum()\n",
    "print(f\"The number of duplicate rows is: {duplicate_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since these are data pertaining to physical characteristics, it may be common for the same type of flower to have the same size of petal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For atypical values, with the .describe() method, you obtain descriptive statistics, such as mean, standard deviation, minimum, maximum, and percentiles, which could indicate the presence of outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       sepal_length  sepal_width  petal_length  petal_width\n",
      "count    150.000000   150.000000    150.000000   150.000000\n",
      "mean       5.843333     3.054000      3.758667     1.198667\n",
      "std        0.828066     0.433594      1.764420     0.763161\n",
      "min        4.300000     2.000000      1.000000     0.100000\n",
      "25%        5.100000     2.800000      1.600000     0.300000\n",
      "50%        5.800000     3.000000      4.350000     1.300000\n",
      "75%        6.400000     3.300000      5.100000     1.800000\n",
      "max        7.900000     4.400000      6.900000     2.500000\n"
     ]
    }
   ],
   "source": [
    "statistics_summary= df.describe()\n",
    "print(statistics_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
